1 wget http://docs.projectcalico.org/v2.3/getting-started/kubernetes/installation/hosted/calico.yaml
 修改文件中 etcd地址 

3  kubectl create -f calico.yaml

4 [root@kubernetes calico_new]# kubectl get pods -n kube-system
NAME                                        READY     STATUS    RESTARTS   AGE
calico-node-2dz49                           2/2       Running   0          17h
calico-node-60rdf                           2/2       Running   0          17h
calico-policy-controller-3020253993-4tx38   1/1       Running   0          17h

5 增加 RBAC权限
vim rule.yaml
kind: ClusterRole
apiVersion: rbac.authorization.k8s.io/v1beta1
metadata:
  name: calico-policy-controller
  namespace: kube-system
rules:
  - apiGroups:
    - ""
    - extensions
    resources:
      - pods
      - namespaces
      - networkpolicies
    verbs:
      - watch
      - list
---
kind: ClusterRoleBinding
apiVersion: rbac.authorization.k8s.io/v1beta1
metadata:
  name: calico-policy-controller
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: calico-policy-controller
subjects:
- kind: ServiceAccount
  name: calico-policy-controller
  namespace: kube-system
---
kind: ClusterRole
apiVersion: rbac.authorization.k8s.io/v1beta1
metadata:
  name: calico-node
  namespace: kube-system
rules:
  - apiGroups: [""]
    resources:
      - pods
      - nodes
    verbs:
      - get
---
apiVersion: rbac.authorization.k8s.io/v1beta1
kind: ClusterRoleBinding
metadata:
  name: calico-node
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: calico-node
subjects:
- kind: ServiceAccount
  name: calico-node
  namespace: kube-system
  
  
 6 权限查看 
 [root@kubernetes calico_new]# kubectl get clusterrolebindings
NAME                                           AGE
calico-node                                    16h
calico-policy-controller                       16h

7 修改kube-apiserver.service
[root@kubernetes calico_new]# vi /lib/systemd/system/kube-apiserver.service 
[Unit]
Description=Kubernetes API Service
Documentation=https://github.com/GoogleCloudPlatform/kubernetes
After=network.target
After=etcd.service

[Service]
EnvironmentFile=-/etc/kubernetes/env.sh
EnvironmentFile=-/etc/kubernetes/config
EnvironmentFile=-/etc/kubernetes/apiserver
ExecStart=/usr/local/bin/kube-apiserver       \
 --admission-control=NamespaceLifecycle,LimitRanger,ServiceAccount,DefaultStorageClass,ResourceQuota \
 --advertise-address=${MASTER_IP} \
 --bind-address=${MASTER_IP} \
 --insecure-bind-address=${MASTER_IP} \
 --authorization-mode=RBAC \
 --runtime-config=rbac.authorization.k8s.io/v1alpha1 \
 --kubelet-https=true \
 --experimental-bootstrap-token-auth \
 --token-auth-file=/etc/kubernetes/token.csv \
 --service-cluster-ip-range=${SERVICE_CIDR} \
 --service-node-port-range=${NODE_PORT_RANGE} \
 --tls-cert-file=/etc/kubernetes/ssl/kubernetes.pem \
 --tls-private-key-file=/etc/kubernetes/ssl/kubernetes-key.pem \
 --client-ca-file=/etc/kubernetes/ssl/ca.pem \
 --service-account-key-file=/etc/kubernetes/ssl/ca-key.pem \
 --etcd-cafile=/etc/kubernetes/ssl/ca.pem \
 --etcd-certfile=/etc/kubernetes/ssl/kubernetes.pem \
 --etcd-keyfile=/etc/kubernetes/ssl/kubernetes-key.pem \
 --etcd-servers=${ETCD_ENDPOINTS} \
 --enable-swagger-ui=true \
 --allow-privileged=true \
 --apiserver-count=3 \
 --audit-log-maxage=30 \
 --audit-log-maxbackup=3 \
 --audit-log-maxsize=100 \
 --audit-log-path=/var/lib/audit.log \
 --event-ttl=1h \
 --v=2
 
 7  配置环境变量文件 /etc/kubernetes/env.sh
 [root@kubernetes calico_new]# cat /etc/kubernetes/env.sh
BOOTSTRAP_TOKEN="3dc3d7185d153eb17277ca0bc9366513" 
SERVICE_CIDR="192.168.244.0/22"
CLUSTER_CIDR="10.10.6.0/24"
NODE_PORT_RANGE="1-65535"
ETCD_ENDPOINTS="http://10.10.0.70:2379,http://10.10.0.73:2379,http://10.10.0.74:2379"
CLUSTER_KUBERNETES_SVC_IP="192.168.244.1"
CLUSTER_DNS_SVC_IP="192.168.244.2"
CLUSTER_DNS_DOMAIN="cluster.local."
NODE_NAME=etcd-host0
NODE_IP=10.10.0.70
NODE_IPS="10.10.0.70,10.10.0.73,10.10.0.74"
ETCD_NODES=etcd-host0=http://10.10.0.70:2380,etcd-host1=http://10.10.0.73:2380,etcd-host2=http://10.10.0.74:2380
MASTER_IP=10.10.0.70
KUBE_APISERVER="https://${MASTER_IP}:6443"

8 配置kubelet.service文件
[root@kubernetes calico_new]# vi /usr/lib/systemd/system/kubelet.service 
[Unit]
Description=Kubernetes Kubelet Server
Documentation=https://github.com/googleCloudPlatform/kubernetes
After=docker.service
Requires=docker.service

[Service]
WorkingDirectory=/var/lib/kubelet
EnvironmentFile=-/etc/kubernetes/env.sh
ExecStart=/usr/bin/kubelet \
 --api-servers=http://10.10.0.70:8080 \
 --address=${NODE_IP} \
 --hostname-override=${NODE_IP} \
 --pod-infra-container-image=registry.access.redhat.com/rhel7/pod-infrastructure:latest \
 --experimental-bootstrap-kubeconfig=/etc/kubernetes/bootstrap.kubeconfig \
 --kubeconfig=/etc/kubernetes/kubelet.kubeconfig \
 --require-kubeconfig \
 --cert-dir=/etc/kubernetes/ssl \
 --cluster-dns=${CLUSTER_DNS_SVC_IP} \
 --cluster-domain=${CLUSTER_DNS_DOMAIN} \
 --hairpin-mode promiscuous-bridge \
 --allow-privileged=true \
 --serialize-image-pulls=false \
 --logtostderr=true \
 --cgroup-driver=systemd \
 --v=2 \
 --allow-privileged=true \
 --network-plugin=cni \
 --network-plugin-dir=/etc/cni/net.d \
 --cni-conf-dir=/etc/cni/net.d \
 --cni-bin-dir=/opt/cni/bin

ExecStopPost=/usr/sbin/iptables -A INPUT -s 172.16.0.0/12  -p tcp --dport 4194 -j ACCEPT
ExecStopPost=/usr/sbin/iptables -A INPUT -s 10.0.0.0/8     -p tcp --dport 4194 -j ACCEPT
ExecStopPost=/usr/sbin/iptables -A INPUT -s 192.168.0.0/16 -p tcp --dport 4194 -j ACCEPT
ExecStopPost=/usr/sbin/iptables -A INPUT                   -p tcp --dport 4194 -j DROP

Restart=on-failure
RestartSec=5

[Install]
WantedBy=multi-user.target


9 下载cni 插件    (kubelet cni插件在所有机器上都要安装，用于calico打路由)
wget -N -P /opt/cni/bin https://github.com/projectcalico/cni-plugin/releases/download/v1.9.1/calico
wget -N -P /opt/cni/bin https://github.com/projectcalico/cni-plugin/releases/download/v1.9.1/calico-ipam
chmod +x /opt/cni/bin/calico /opt/cni/bin/calico-ipam
wget https://github.com/projectcalico/calicoctl/releases/download/v1.3.0/calicoctl
chmod +x calicoctl

wget https://github.com/containernetworking/cni/releases/download/v0.4.0/cni-v0.4.0.tgz
tar -zxvf cni-v0.4.0.tgz
cp loopback /opt/cni/bin/


10 生成pod 测试 
#centos-rcd.yaml
apiVersion: v1
kind: ReplicationController
metadata:
  name: centos
  labels:
    name: centos
spec:
  replicas: 1
  template:
    metadata:
      labels:
        name: centos
    spec:
      containers:
      - name: centos
        image: index.tenxcloud.com/tenxcloud/docker-centos
        ports:
        - containerPort: 6379
      nodeSelector:
        kubernetes.io/hostname: "192.168.99.130"
        
2、部署redis，指定部署在192.168.99.131节点上，redis-rc.yaml如下：

apiVersion: v1
kind: ReplicationController
metadata:
  name: redis
  labels:
    k8s-app: redis
spec:
  replicas: 1
  selector:
    k8s-app: redis
  template:
    metadata:
      labels:
        k8s-app: redis
    spec:
      containers:
      - name: redis
        image: 10.10.30.166/public/redis:v1
        ports:
        - containerPort: 6379
          name: redis-tcp
          protocol: TCP
      nodeSelector:
        kubernetes.io/hostname: "192.168.99.131"
redis-svc.yaml如下：

apiVersion: v1
kind: Service
metadata:
  name: redis
spec:
  selector:
    k8s-app: redis
  clusterIP: 10.254.159.20
  ports:
  - name: "1"
    port: 6379
    protocol: TCP        

11 机器上路由
[root@kubernetes calico_new]# route -n
Kernel IP routing table
Destination     Gateway         Genmask         Flags Metric Ref    Use Iface
0.0.0.0         115.182.58.1    0.0.0.0         UG    425    0        0 eth0
10.10.0.0       0.0.0.0         255.255.248.0   U     425    0        0 eth1
10.10.64.0      0.0.0.0         255.255.254.0   U     425    0        0 eth2
10.10.254.0     0.0.0.0         255.255.255.192 U     0      0        0 *
10.10.254.22    0.0.0.0         255.255.255.255 UH    0      0        0 calie6777031d6e


[root@node1 ~]# route -n 
Kernel IP routing table
Destination     Gateway         Genmask         Flags Metric Ref    Use Iface
0.0.0.0         115.182.58.1    0.0.0.0         UG    425    0        0 eth0
10.10.0.0       0.0.0.0         255.255.248.0   U     425    0        0 eth1
10.10.64.0      0.0.0.0         255.255.254.0   U     425    0        0 eth2
10.10.254.0     10.10.0.70      255.255.255.192 UG    0      0        0 eth1
10.10.254.192   0.0.0.0         255.255.255.192 U     0      0        0 *
10.10.254.215   0.0.0.0         255.255.255.255 UH    0      0        0 calia9ad2aa4efb
10.10.254.216   0.0.0.0         255.255.255.255 UH    0      0        0 calid81dca27a3d


 
 ###  calico.yaml 文件示例 #### 
[root@kubernetes calico_new]# cat calico.yaml
# Calico Version v2.3.0
# http://docs.projectcalico.org/v2.3/releases#v2.3.0
# This manifest includes the following component versions:
#   calico/node:v1.3.0
#   calico/cni:v1.9.1
#   calico/kube-policy-controller:v0.6.0

# This ConfigMap is used to configure a self-hosted Calico installation.
kind: ConfigMap
apiVersion: v1
metadata:
  name: calico-config
  namespace: kube-system
data:
  # Configure this with the location of your etcd cluster.
  etcd_endpoints: "http://127.0.0.1:2379"

  # Configure the Calico backend to use.
  calico_backend: "bird"

  # The CNI network configuration to install on each node.
  cni_network_config: |-
    {
        "name": "k8s-pod-network",
        "cniVersion": "0.1.0",
        "type": "calico",
        "etcd_endpoints": "__ETCD_ENDPOINTS__",
        "etcd_key_file": "__ETCD_KEY_FILE__",
        "etcd_cert_file": "__ETCD_CERT_FILE__",
        "etcd_ca_cert_file": "__ETCD_CA_CERT_FILE__",
        "log_level": "info",
        "ipam": {
            "type": "calico-ipam"
        },
        "policy": {
            "type": "k8s",
            "k8s_api_root": "https://__KUBERNETES_SERVICE_HOST__:__KUBERNETES_SERVICE_PORT__",
            "k8s_auth_token": "__SERVICEACCOUNT_TOKEN__"
        },
        "kubernetes": {
            "kubeconfig": "__KUBECONFIG_FILEPATH__"
        }
    }

  # If you're using TLS enabled etcd uncomment the following.
  # You must also populate the Secret below with these files.
  etcd_ca: ""   # "/calico-secrets/etcd-ca"
  etcd_cert: "" # "/calico-secrets/etcd-cert"
  etcd_key: ""  # "/calico-secrets/etcd-key"

---

# The following contains k8s Secrets for use with a TLS enabled etcd cluster.
# For information on populating Secrets, see http://kubernetes.io/docs/user-guide/secrets/
apiVersion: v1
kind: Secret
type: Opaque
metadata:
  name: calico-etcd-secrets
  namespace: kube-system
data:
  # Populate the following files with etcd TLS configuration if desired, but leave blank if
  # not using TLS for etcd.
  # This self-hosted install expects three files with the following names.  The values
  # should be base64 encoded strings of the entire contents of each file.
  # etcd-key: null
  # etcd-cert: null
  # etcd-ca: null

---

# This manifest installs the calico/node container, as well
# as the Calico CNI plugins and network config on
# each master and worker node in a Kubernetes cluster.
kind: DaemonSet
apiVersion: extensions/v1beta1
metadata:
  name: calico-node
  namespace: kube-system
  labels:
    k8s-app: calico-node
spec:
  selector:
    matchLabels:
      k8s-app: calico-node
  template:
    metadata:
      labels:
        k8s-app: calico-node
      annotations:
        scheduler.alpha.kubernetes.io/critical-pod: ''
        scheduler.alpha.kubernetes.io/tolerations: |
          [{"key": "dedicated", "value": "master", "effect": "NoSchedule" },
           {"key":"CriticalAddonsOnly", "operator":"Exists"}]
    spec:
      hostNetwork: true
      serviceAccountName: calico-node
      containers:
        # Runs calico/node container on each Kubernetes node.  This
        # container programs network policy and routes on each
        # host.
        - name: calico-node
          image: quay.io/calico/node:v1.3.0
          env:
            # The location of the Calico etcd cluster.
            - name: ETCD_ENDPOINTS
              valueFrom:
                configMapKeyRef:
                  name: calico-config
                  key: etcd_endpoints
            # Choose the backend to use.
            - name: CALICO_NETWORKING_BACKEND
              valueFrom:
                configMapKeyRef:
                  name: calico-config
                  key: calico_backend
            # Disable file logging so `kubectl logs` works.
            - name: CALICO_DISABLE_FILE_LOGGING
              value: "true"
            # Set Felix endpoint to host default action to ACCEPT.
            - name: FELIX_DEFAULTENDPOINTTOHOSTACTION
              value: "ACCEPT"
            # Configure the IP Pool from which Pod IPs will be chosen.
            - name: CALICO_IPV4POOL_CIDR
              value: "10.10.252.0/24"
            - name: CALICO_IPV4POOL_IPIP
              value: "always"
            # Disable IPv6 on Kubernetes.
            - name: FELIX_IPV6SUPPORT
              value: "false"
            # Set Felix logging to "info"
            - name: FELIX_LOGSEVERITYSCREEN
              value: "info"
            # Location of the CA certificate for etcd.
            - name: ETCD_CA_CERT_FILE
              valueFrom:
                configMapKeyRef:
                  name: calico-config
                  key: etcd_ca
            # Location of the client key for etcd.
            - name: ETCD_KEY_FILE
              valueFrom:
                configMapKeyRef:
                  name: calico-config
                  key: etcd_key
            # Location of the client certificate for etcd.
            - name: ETCD_CERT_FILE
              valueFrom:
                configMapKeyRef:
                  name: calico-config
                  key: etcd_cert
            # Auto-detect the BGP IP address.
            - name: IP
              value: ""
          securityContext:
            privileged: true
          resources:
            requests:
              cpu: 250m
          volumeMounts:
            - mountPath: /lib/modules
              name: lib-modules
              readOnly: true
            - mountPath: /var/run/calico
              name: var-run-calico
              readOnly: false
            - mountPath: /calico-secrets
              name: etcd-certs
        # This container installs the Calico CNI binaries
        # and CNI network config file on each node.
        - name: install-cni
          image: quay.io/calico/cni:v1.9.1
          command: ["/install-cni.sh"]
          env:
            # The location of the Calico etcd cluster.
            - name: ETCD_ENDPOINTS
              valueFrom:
                configMapKeyRef:
                  name: calico-config
                  key: etcd_endpoints
            # The CNI network config to install on each node.
            - name: CNI_NETWORK_CONFIG
              valueFrom:
                configMapKeyRef:
                  name: calico-config
                  key: cni_network_config
          volumeMounts:
            - mountPath: /host/opt/cni/bin
              name: cni-bin-dir
            - mountPath: /host/etc/cni/net.d
              name: cni-net-dir
            - mountPath: /calico-secrets
              name: etcd-certs
      volumes:
        # Used by calico/node.
        - name: lib-modules
          hostPath:
            path: /lib/modules
        - name: var-run-calico
          hostPath:
            path: /var/run/calico
        # Used to install CNI.
        - name: cni-bin-dir
          hostPath:
            path: /opt/cni/bin
        - name: cni-net-dir
          hostPath:
            path: /etc/cni/net.d
        # Mount in the etcd TLS secrets.
        - name: etcd-certs
          secret:
            secretName: calico-etcd-secrets

---

# This manifest deploys the Calico policy controller on Kubernetes.
# See https://github.com/projectcalico/k8s-policy
apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: calico-policy-controller
  namespace: kube-system
  labels:
    k8s-app: calico-policy
  annotations:
    scheduler.alpha.kubernetes.io/critical-pod: ''
    scheduler.alpha.kubernetes.io/tolerations: |
      [{"key": "dedicated", "value": "master", "effect": "NoSchedule" },
       {"key":"CriticalAddonsOnly", "operator":"Exists"}]
spec:
  # The policy controller can only have a single active instance.
  replicas: 1
  strategy:
    type: Recreate
  template:
    metadata:
      name: calico-policy-controller
      namespace: kube-system
      labels:
        k8s-app: calico-policy
    spec:
      # The policy controller must run in the host network namespace so that
      # it isn't governed by policy that would prevent it from working.
      hostNetwork: true
      serviceAccountName: calico-policy-controller
      containers:
        - name: calico-policy-controller
          image: quay.io/calico/kube-policy-controller:v0.6.0
          env:
            # The location of the Calico etcd cluster.
            - name: ETCD_ENDPOINTS
              valueFrom:
                configMapKeyRef:
                  name: calico-config
                  key: etcd_endpoints
            # Location of the CA certificate for etcd.
            - name: ETCD_CA_CERT_FILE
              valueFrom:
                configMapKeyRef:
                  name: calico-config
                  key: etcd_ca
            # Location of the client key for etcd.
            - name: ETCD_KEY_FILE
              valueFrom:
                configMapKeyRef:
                  name: calico-config
                  key: etcd_key
            # Location of the client certificate for etcd.
            - name: ETCD_CERT_FILE
              valueFrom:
                configMapKeyRef:
                  name: calico-config
                  key: etcd_cert
            # The location of the Kubernetes API.  Use the default Kubernetes
            # service for API access.
            - name: K8S_API
              value: "https://kubernetes.default:443"
            # Since we're running in the host namespace and might not have KubeDNS
            # access, configure the container's /etc/hosts to resolve
            # kubernetes.default to the correct service clusterIP.
            - name: CONFIGURE_ETC_HOSTS
              value: "true"
          volumeMounts:
            # Mount in the etcd TLS secrets.
            - mountPath: /calico-secrets
              name: etcd-certs
      volumes:
        # Mount in the etcd TLS secrets.
        - name: etcd-certs
          secret:
            secretName: calico-etcd-secrets

---

apiVersion: v1
kind: ServiceAccount
metadata:
  name: calico-policy-controller
  namespace: kube-system

---

apiVersion: v1
kind: ServiceAccount
metadata:
  name: calico-node
  namespace: kube-system
